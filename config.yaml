# Agile Agent Team Experiment Configuration

experiment:
  name: "baseline-experiment"
  sprint_duration_minutes: 20
  sprints_per_stakeholder_review: 5

team:
  config_dir: "team_config"

  wip_limits:
    in_progress: 4
    review: 2

  quality_gates:
    min_test_coverage_lines: 85
    min_test_coverage_branches: 80
    max_cyclomatic_complexity: 10

  definition_of_done:
    - "All acceptance criteria met"
    - "Test coverage >= 85%"
    - "All tests passing"
    - "Code reviewed by pair"
    - "Deployed to staging"
    - "PO acceptance"

disturbances:
  enabled: true

  frequencies:
    dependency_breaks: 0.166  # 1 in 6 sprints
    production_incident: 0.125  # 1 in 8 sprints  
    flaky_test: 0.25  # 1 in 4 sprints
    scope_creep: 0.20  # 1 in 5 sprints
    junior_misunderstanding: 0.33  # 1 in 3 sprints
    architectural_debt_surfaces: 0.166  # 1 in 6 sprints

  blast_radius_controls:
    max_velocity_impact: 0.30  # Max 30% velocity drop
    max_quality_regression: 0.15  # Max 15% coverage drop

models:
  vllm_endpoint: "http://vllm-gh200-module-1:8000"

# Runtime configurations for tool-using agents
runtimes:
  # Anthropic (Claude) runtime - requires API key and internet
  anthropic:
    enabled: true
    api_key_env: "ANTHROPIC_API_KEY"
    default_model: "claude-sonnet-4-5"
    fallback_model: "claude-opus-4-6"
    max_tokens: 8192

  # Local vLLM runtime - fully offline, uses self-hosted models
  local_vllm:
    enabled: true
    endpoint: "http://vllm-gh200-module-1:8000"
    tool_use_protocol: "xml"  # XML-based tool calling
    max_tokens: 8192
    temperature: 0.7

  # Shared tool configuration
  tools:
    workspace_root: "/tmp/agent-workspace"  # Base directory for code generation
    allowed_commands:
      - "git"
      - "pytest"
      - "python"
      - "pip"
      - "mypy"
      - "black"
      - "ruff"
      - "npm"
      - "node"
      - "ls"
      - "cat"
      - "grep"
      - "find"
      - "mkdir"
      - "echo"
    blocked_patterns:
      - "rm -rf /"
      - "dd if="
      - "mkfs"
      - "sudo"
      - "curl.*|.*bash"
      - "wget.*|.*sh"

# Agent definitions using new compositional structure
# Each agent = individual personality + seniority + specialization(s) + role archetype
models:
  agents:
    alex_senior_networking:
      name: "Alex Chen (Senior Networking Specialist)"
      individual: alex_chen
      seniority: senior
      specializations: [networking, security]
      role_archetype: developer+leader
      demographics:
        pronouns: "he/him"
        cultural_background: "Chinese-American"
      runtime: "local_vllm"  # Can use: local_vllm | anthropic
      tools: ["filesystem", "git", "bash"]  # Available tools
      model: "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct"
      temperature: 0.7
      max_tokens: 3072

    priya_senior_devops:
      name: "Priya Sharma (Senior DevOps Specialist)"
      individual: priya_sharma
      seniority: senior
      specializations: [devops, cloud_architecture]
      role_archetype: developer
      demographics:
        pronouns: "she/her"
        cultural_background: "Indian"
      runtime: "local_vllm"
      tools: ["filesystem", "git", "bash"]
      model: "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct"
      temperature: 0.7
      max_tokens: 3072

    marcus_mid_backend:
      name: "Marcus Okafor (Mid-Level Backend Developer)"
      individual: marcus_okafor
      seniority: mid
      specializations: [backend, api_design]
      role_archetype: developer
      demographics:
        pronouns: "he/him"
        cultural_background: "Nigerian"
      runtime: "local_vllm"
      tools: ["filesystem", "git"]
      model: "Qwen/Qwen2.5-Coder-14B-Instruct"
      temperature: 0.7
      max_tokens: 2048

    elena_mid_frontend:
      name: "Elena Volkov (Mid-Level Frontend Developer)"
      individual: elena_volkov
      seniority: mid
      specializations: [frontend, ui_ux]
      role_archetype: developer
      demographics:
        pronouns: "she/her"
        cultural_background: "Russian"
      runtime: "local_vllm"
      tools: ["filesystem", "git"]
      model: "Qwen/Qwen2.5-Coder-14B-Instruct"
      temperature: 0.7
      max_tokens: 2048

    jamie_junior_fullstack:
      name: "Jamie Rodriguez (Junior Full-Stack Developer)"
      individual: jamie_rodriguez
      seniority: junior
      specializations: [backend, frontend]
      role_archetype: developer
      demographics:
        pronouns: "they/them"
        cultural_background: "Mexican-American"
      runtime: "local_vllm"
      tools: ["filesystem"]  # Limited tools for juniors
      model: "Qwen/Qwen2.5-Coder-7B-Instruct"
      temperature: 0.8
      max_tokens: 2048

    jordan_junior_backend:
      name: "Jordan Kim (Junior Backend Developer)"
      individual: jordan_kim
      seniority: junior
      specializations: [backend, database]
      role_archetype: developer
      demographics:
        pronouns: "he/him"
        cultural_background: "Korean-American"
      runtime: "local_vllm"
      tools: ["filesystem"]
      model: "Qwen/Qwen2.5-Coder-7B-Instruct"
      temperature: 0.8
      max_tokens: 2048

    yuki_senior_tester_integration:
      name: "Yuki Tanaka (Senior Integration Tester)"
      individual: yuki_tanaka
      seniority: senior
      specializations: [test_automation, backend]
      role_archetype: tester
      demographics:
        pronouns: "they/them"
        cultural_background: "Japanese"
      runtime: "local_vllm"
      tools: ["filesystem", "bash"]  # Testers need to run tests
      model: "Qwen/Qwen2.5-14B-Instruct"
      temperature: 0.7
      max_tokens: 2048

    maria_mid_tester_e2e:
      name: "Maria Santos (Mid-Level E2E Tester)"
      individual: maria_santos
      seniority: mid
      specializations: [test_automation, frontend]
      role_archetype: tester
      demographics:
        pronouns: "she/her"
        cultural_background: "Brazilian"
      runtime: "local_vllm"
      tools: ["filesystem", "bash"]
      model: "Qwen/Qwen2.5-14B-Instruct"
      temperature: 0.7
      max_tokens: 2048

    sophie_senior_qa_lead:
      name: "Sophie Dubois (QA Lead)"
      individual: sophie_dubois
      seniority: senior
      specializations: [test_automation, performance_optimization]
      role_archetype: tester+leader
      demographics:
        pronouns: "she/her"
        cultural_background: "French"
      runtime: "local_vllm"
      tools: ["filesystem", "git", "bash"]
      model: "Qwen/Qwen2.5-72B-Instruct"
      temperature: 0.7
      max_tokens: 4096

    ahmed_senior_dev_lead:
      name: "Ahmed Hassan (Development Lead)"
      individual: ahmed_hassan
      seniority: senior
      specializations: [backend, distributed_systems]
      role_archetype: developer+leader
      demographics:
        pronouns: "he/him"
        cultural_background: "Egyptian"
      runtime: "local_vllm"
      tools: ["filesystem", "git", "bash"]
      model: "Qwen/Qwen2.5-Coder-32B-Instruct"
      temperature: 0.7
      max_tokens: 4096

    alex_senior_po:
      name: "Alex Chen (Product Owner)"
      individual: alex_chen  # Reusing personality (allowed)
      seniority: senior
      specializations: [api_design]
      role_archetype: leader
      demographics:
        pronouns: "he/him"
        cultural_background: "Chinese-American"
      runtime: "local_vllm"
      tools: ["filesystem"]  # PO only needs to read, not write
      model: "Qwen/Qwen2.5-72B-Instruct"
      temperature: 0.8
      max_tokens: 4096

database:
  url: "postgresql://postgres:password@shared-db:5432/team_context"
  redis_url: "redis://redis:6379"

monitoring:
  prometheus_port: 8080
  grafana_url: "http://grafana:3000"

profile_swapping:
  mode: "constrained"  # none | constrained | free

  allowed_scenarios:
    - "critical_production_incident"
    - "specialist_unavailable"
    - "deliberate_cross_training"

  penalties:
    context_switch_slowdown: 1.20  # 20% slower first task
    proficiency_reduction: 0.70  # 70% of true specialist
    knowledge_decay_sprints: 1  # Decays after 1 sprint if not used
